{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "@njit\n",
    "def calculate_weights_numba(d, thresh):\n",
    "    w = [1.0]\n",
    "    k = 1\n",
    "    while True:\n",
    "        w_ = -w[-1] * (d - k + 1) / k\n",
    "        if abs(w_) < thresh:\n",
    "            break\n",
    "        w.append(w_)\n",
    "        k += 1\n",
    "    return np.array(w[::-1])\n",
    "\n",
    "@njit\n",
    "def frac_diff_numba(series_values, w, width):\n",
    "    n = len(series_values)\n",
    "    diff_series = np.empty(n)\n",
    "    diff_series[:] = np.nan\n",
    "    for i in range(width, n):\n",
    "        diff_value = 0.0\n",
    "        for j in range(width):\n",
    "            diff_value += w[j] * series_values[i - width + j]\n",
    "        diff_series[i] = diff_value\n",
    "    return diff_series\n",
    "\n",
    "def frac_diff_optimized(series, d, thresh=1e-5):\n",
    "    \"\"\"\n",
    "    Aplica diferenciação fracionária à série temporal utilizando Numba para otimização.\n",
    "\n",
    "    Parâmetros:\n",
    "    - series: pd.Series, a série temporal a ser diferenciada.\n",
    "    - d: float, ordem de diferenciação fracionária (0 < d < 1).\n",
    "    - thresh: float, limiar para os coeficientes binomiais.\n",
    "\n",
    "    Retorna:\n",
    "    - pd.Series, série diferenciada fracionariamente.\n",
    "    \"\"\"\n",
    "    # Calcular os coeficientes binomiais\n",
    "    w = calculate_weights_numba(d, thresh)\n",
    "    width = len(w)\n",
    "    \n",
    "    # Converter a série para um array numpy\n",
    "    series_values = series.values\n",
    "    n = len(series_values)\n",
    "    \n",
    "    # Aplicar a diferenciação fracionária utilizando Numba\n",
    "    diff_series = frac_diff_numba(series_values, w, width)\n",
    "    \n",
    "    return pd.Series(diff_series, index=series.index)\n",
    "\n",
    "def adf_test(series, title='ADF Test'):\n",
    "    \"\"\"\n",
    "    Realiza o teste de Dickey-Fuller aumentado e imprime os resultados.\n",
    "\n",
    "    Parâmetros:\n",
    "    - series: pd.Series, a série temporal a ser testada.\n",
    "    - title: str, título para identificar o teste.\n",
    "\n",
    "    Retorna:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(f'\\n==== {title} ====')\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    labels = ['Estatística ADF', 'p-valor', 'Número de Lags Usados', 'Número de Observações Usadas']\n",
    "    out = pd.Series(result[0:4], index=labels)\n",
    "    for key, value in result[4].items():\n",
    "        out[f'Valor Crítico ({key})'] = value\n",
    "    print(out.to_string())\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Evidência forte contra a hipótese nula (presença de raiz unitária), rejeitamos a hipótese nula.\")\n",
    "    else:\n",
    "        print(\"Evidência fraca contra a hipótese nula, não rejeitamos a hipótese nula.\")\n",
    "\n",
    "def create_lag_matrix(series, n_lags):\n",
    "    \"\"\"\n",
    "    Cria uma matriz de lags para a série temporal.\n",
    "\n",
    "    Parâmetros:\n",
    "    - series: pd.Series, a série temporal.\n",
    "    - n_lags: int, número de lags a serem criados.\n",
    "\n",
    "    Retorna:\n",
    "    - X: np.ndarray, matriz de lags.\n",
    "    - y: np.ndarray, variável alvo ajustada.\n",
    "    \"\"\"\n",
    "    # Criar um DataFrame com as lags\n",
    "    df_lags = pd.concat([series.shift(i) for i in range(1, n_lags + 1)], axis=1)\n",
    "    df_lags.columns = [f'lag_{i}' for i in range(1, n_lags + 1)]\n",
    "    \n",
    "    # Remover linhas com NaN causados pelo shift\n",
    "    df_lags = df_lags.dropna()\n",
    "    \n",
    "    # Variável alvo\n",
    "    y = series.loc[df_lags.index].values\n",
    "    \n",
    "    # Converter para array NumPy\n",
    "    X = df_lags.values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def monteCarlo(serie_predita, constant, params, order):\n",
    "    out = len(serie_predita)\n",
    "    Y = np.zeros(out)\n",
    "    Y[:(order)] = serie_predita.iloc[:(order)]\n",
    "\n",
    "    for i in range(order, out):\n",
    "        # Extract the relevant data and transpose if needed\n",
    "        data = serie_predita.iloc[i-order:i].values\n",
    "        phi_transpose = np.transpose(params)\n",
    "\n",
    "        Y[i] = data @ phi_transpose + constant\n",
    "\n",
    "    Y = pd.DataFrame(Y)\n",
    "    Y.index = serie_predita.index\n",
    "    Y.rename(columns={0: 'fraqdiff_pred'}, inplace=True)\n",
    "    return Y\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def auto_reg(order, serie_predita):\n",
    "    \"\"\"\n",
    "    Ajusta um modelo autoregressivo e retorna previsões alinhadas com a série original.\n",
    "\n",
    "    Parameters:\n",
    "    - order (int): Ordem do modelo autoregressivo.\n",
    "    - serie_predita (pd.Series): Série temporal para ajustar o modelo.\n",
    "\n",
    "    Returns:\n",
    "    - Y_pred_aligned (pd.Series): Série de previsões alinhadas com a série original.\n",
    "    - constant (float): Constante do modelo.\n",
    "    - params (pd.Series): Parâmetros do modelo.\n",
    "    \"\"\"\n",
    "    # Garantir que serie_predita é uma pandas Series\n",
    "    if not isinstance(serie_predita, pd.Series):\n",
    "        serie_predita = pd.Series(serie_predita)\n",
    "    \n",
    "    # Criar matriz de lags sem usar np.roll para evitar deslocamento circular\n",
    "    X = pd.concat([serie_predita.shift(i+1) for i in range(order)], axis=1)\n",
    "    X.columns = [f'lag_{i+1}' for i in range(order)]\n",
    "    \n",
    "    # Remover linhas com NaN devido aos lags\n",
    "    X = X.dropna()\n",
    "    y = serie_predita.loc[X.index]\n",
    "    \n",
    "    # Adicionar constante\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Ajustar o modelo autoregressivo\n",
    "    model = sm.OLS(y, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    # Exibir o resumo do modelo\n",
    "    print(result.summary())\n",
    "    \n",
    "    # Obter parâmetros\n",
    "    constant = result.params['const']\n",
    "    params = result.params.drop('const')\n",
    "    \n",
    "    # Prever os valores in-sample\n",
    "    Y_pred = result.predict(X)\n",
    "    \n",
    "    # Garantir que Y_pred está alinhado com y\n",
    "    Y_pred_aligned = Y_pred.copy()\n",
    "    Y_pred_aligned.index = y.index\n",
    "    \n",
    "    return Y_pred_aligned, constant, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_parquet(\"../output/dollar-bars-[10000000]/dollar_bars.parquet/part.0.parquet\")\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Função de diferenciação fracionária otimizada com Numba\n",
    "@njit\n",
    "def frac_diff_numba(series, w, width):\n",
    "    diff_series = np.zeros(len(series))\n",
    "    for i in range(width, len(series)):\n",
    "        value = 0.0\n",
    "        for j in range(width):\n",
    "            value += w[j] * series[i - j]\n",
    "        diff_series[i] = value\n",
    "    return diff_series\n",
    "\n",
    "def frac_diff_optimized(series, d, max_lag=100):\n",
    "    # Calcula os pesos da diferenciação fracionária\n",
    "    w = [1.0]\n",
    "    for k in range(1, max_lag):\n",
    "        w_ = -w[-1] * (d - k + 1) / k\n",
    "        w.append(w_)\n",
    "        if abs(w[-1]) < 1e-5:\n",
    "            break\n",
    "    width = len(w)\n",
    "    series_values = series.values.astype(np.float64)  # Assegura que os valores são float64\n",
    "    diff_series = frac_diff_numba(series_values, np.array(w, dtype=np.float64), width)\n",
    "    return pd.Series(diff_series, index=series.index)\n",
    "\n",
    "# Função para realizar o teste ADF\n",
    "def adf_test(series, title=''):\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'== {title} ==')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'Critical Value {key}: {value}')\n",
    "    print('')\n",
    "\n",
    "# Função para criar matriz de lags\n",
    "def create_lag_matrix(series, n_lags):\n",
    "    X = pd.concat([series.shift(i) for i in range(1, n_lags + 1)], axis=1)\n",
    "    y = series\n",
    "    X = X.dropna()\n",
    "    y = y.loc[X.index]\n",
    "    return X.values, y.values\n",
    "\n",
    "# Função autoregressiva (exemplo simples)\n",
    "def auto_reg(order, series):\n",
    "    from statsmodels.tsa.ar_model import AutoReg\n",
    "    model = AutoReg(series, lags=order, old_names=False)\n",
    "    model_fit = model.fit()\n",
    "    Y_pred = model_fit.predict(start=order, end=len(series)-1)\n",
    "    constant = model_fit.params[0]\n",
    "    params = model_fit.params[1:]\n",
    "    return Y_pred, constant, params\n",
    "\n",
    "# Leitura da série\n",
    "series = pd.read_parquet(\"../output/dollar-bars-[10000000]/dollar_bars.parquet/part.0.parquet\")\n",
    "print(series.head())\n",
    "\n",
    "# Definir o valor de diferenciação fracionária\n",
    "d = 0.3\n",
    "\n",
    "# Aplicar a diferenciação fracionária na coluna 'price_close' em vez do DataFrame completo\n",
    "print(\"Aplicando diferenciação fracionária na série 'price_close'...\")\n",
    "series_frac_diff = frac_diff_optimized(series['price_close'], d).dropna()\n",
    "print(\"Diferenciação fracionária concluída.\")\n",
    "\n",
    "# Realizar o teste ADF na série diferenciada completa\n",
    "adf_test(series_frac_diff, title=f'Preço de Fechamento (price_close) - Diferenciação Fracionária d={d}')\n",
    "\n",
    "# Exibir as primeiras linhas da série diferenciada\n",
    "display(series_frac_diff.head())\n",
    "\n",
    "# Definir o tamanho da amostra (5% dos dados)\n",
    "sample_size = int(len(series_frac_diff) * 0.05)  # Aumentado para 5%\n",
    "series_frac_diff_sample = series_frac_diff.sample(n=sample_size, random_state=42).sort_index()\n",
    "\n",
    "# Realizar o teste ADF na amostra de 5%\n",
    "adf_test(series_frac_diff_sample, title=f'Preço de Fechamento (price_close) - Diferenciação Fracionária d={d} (5% Amostra)')\n",
    "\n",
    "# Exibir as primeiras linhas da amostra diferenciada\n",
    "display(series_frac_diff_sample.head())\n",
    "\n",
    "# Criar matriz de lags\n",
    "n_lags = 5\n",
    "X, y = create_lag_matrix(series_frac_diff, n_lags)\n",
    "print(f\"Matriz de lags criada com forma: {X.shape}\")\n",
    "print(f\"Variável alvo (y) criada com forma: {y.shape}\")\n",
    "\n",
    "# Aplicar PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Variância explicada acumulada:\", cumulative_variance)\n",
    "\n",
    "# Determinar número de componentes\n",
    "n_components_var = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Número ótimo de componentes (95% da variância explicada): {n_components_var}\")\n",
    "\n",
    "# Reduzir dimensionalidade\n",
    "n_components = n_components_var\n",
    "pca_reduced = PCA(n_components=n_components)\n",
    "X_reduced = pca_reduced.fit_transform(X_scaled)\n",
    "print(f\"Forma da matriz após PCA: {X_reduced.shape}\")\n",
    "\n",
    "# Aplicação em modelagem\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_reduced, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE médio (5-fold CV): {-np.mean(scores):.4f}\")\n",
    "\n",
    "# Plotar ACF e PACF\n",
    "desired_lags = 40\n",
    "sample_size = len(series_frac_diff_sample)\n",
    "max_allowed_lags = sample_size // 2 - 1\n",
    "adjusted_lags = min(desired_lags, max_allowed_lags)\n",
    "\n",
    "print(f\"Usando lags={adjusted_lags} para a amostra de tamanho {sample_size}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Série Completa\n",
    "plot_acf(series_frac_diff, ax=axes[0, 0], lags=desired_lags, zero=False)\n",
    "axes[0, 0].set_title(f'ACF - Série Completa (d={d})')\n",
    "\n",
    "plot_pacf(series_frac_diff, ax=axes[1, 0], lags=desired_lags, zero=False, method='ywm')\n",
    "axes[1, 0].set_title(f'PACF - Série Completa (d={d})')\n",
    "\n",
    "# Amostra de 5%\n",
    "plot_acf(series_frac_diff_sample, ax=axes[0, 1], lags=adjusted_lags, zero=False)\n",
    "axes[0, 1].set_title(f'ACF - 5% Amostra (d={d})')\n",
    "\n",
    "plot_pacf(series_frac_diff_sample, ax=axes[1, 1], lags=adjusted_lags, zero=False, method='ywm')\n",
    "axes[1, 1].set_title(f'PACF - 5% Amostra (d={d})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Aplicar a função autoregressiva\n",
    "order = 1  # Defina a ordem do modelo autoregressivo\n",
    "Y_pred, constant, params = auto_reg(order, series_frac_diff)\n",
    "\n",
    "# Visualizar a série prevista\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(series_frac_diff, label='Série Diferenciada Fracionária', alpha=0.5)\n",
    "plt.plot(Y_pred, label='Série Prevista', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('Comparação entre Série Diferenciada e Série Prevista')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Diferenciado')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resíduos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Converter y para pandas Series\n",
    "y_series = pd.Series(y, name='y_true')\n",
    "\n",
    "# Verificar se Y_pred é um DataFrame com uma única coluna\n",
    "if isinstance(Y_pred, pd.DataFrame):\n",
    "    if Y_pred.shape[1] == 1:\n",
    "        # Converter para Series\n",
    "        Y_pred_series = Y_pred.iloc[:, 0].reset_index(drop=True)\n",
    "        Y_pred_series.name = 'y_pred'\n",
    "        print(f\"Convertido Y_pred para Series com comprimento {len(Y_pred_series)}.\")\n",
    "    else:\n",
    "        raise ValueError(\"Y_pred possui mais de uma coluna. Por favor, selecione a coluna correta para as previsões.\")\n",
    "elif isinstance(Y_pred, pd.Series):\n",
    "    Y_pred_series = Y_pred.reset_index(drop=True)\n",
    "    Y_pred_series.name = 'y_pred'\n",
    "    print(f\"Y_pred já é uma Series com comprimento {len(Y_pred_series)}.\")\n",
    "else:\n",
    "    raise TypeError(\"Y_pred deve ser uma pandas Series ou DataFrame.\")\n",
    "\n",
    "# Verificar comprimentos\n",
    "len_y = len(y_series)\n",
    "len_Y_pred = len(Y_pred_series)\n",
    "\n",
    "print(f\"Comprimento de y_series: {len_y}\")\n",
    "print(f\"Comprimento de Y_pred_series: {len_Y_pred}\")\n",
    "\n",
    "# Calcular a diferença de comprimento\n",
    "diff = len_Y_pred - len_y\n",
    "\n",
    "if diff > 0:\n",
    "    print(f\"Y_pred_series é {diff} pontos maior que y_series. Truncando os últimos {diff} pontos de Y_pred_series.\")\n",
    "    Y_pred_aligned = Y_pred_series.iloc[:-diff].reset_index(drop=True)\n",
    "    y_aligned = y_series.reset_index(drop=True)\n",
    "elif diff < 0:\n",
    "    print(f\"Y_pred_series é {abs(diff)} pontos menor que y_series. Truncando os últimos {abs(diff)} pontos de y_series.\")\n",
    "    y_aligned = y_series.iloc[:len_Y_pred].reset_index(drop=True)\n",
    "    Y_pred_aligned = Y_pred_series.reset_index(drop=True)\n",
    "else:\n",
    "    print(\"y_series e Y_pred_series já estão alinhadas em comprimento.\")\n",
    "    y_aligned = y_series.reset_index(drop=True)\n",
    "    Y_pred_aligned = Y_pred_series.reset_index(drop=True)\n",
    "\n",
    "print(f\"Comprimento de y_aligned: {len(y_aligned)}\")\n",
    "print(f\"Comprimento de Y_pred_aligned: {len(Y_pred_aligned)}\")\n",
    "\n",
    "\n",
    "# Calcular os resíduos\n",
    "residuals = y_aligned - Y_pred_aligned\n",
    "\n",
    "# Exibir as primeiras linhas dos resíduos\n",
    "display(residuals.head())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Plotar os resíduos ao longo do tempo\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(residuals, label='Resíduos (y_true - Y_pred)')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Resíduos da Previsão Autoregressiva')\n",
    "plt.xlabel('Observações')\n",
    "plt.ylabel('Resíduo')\n",
    "plt.show()\n",
    "\n",
    "# Estatísticas descritivas dos resíduos\n",
    "print(\"Estatísticas dos Resíduos:\")\n",
    "print(residuals.describe())\n",
    "\n",
    "# Plotar histograma dos resíduos\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(residuals, kde=True, bins=50)\n",
    "plt.title('Distribuição dos Resíduos')\n",
    "plt.xlabel('Resíduo')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n",
    "\n",
    "# Teste de normalidade (Shapiro-Wilk)\n",
    "# Shapiro-Wilk tem limite de amostra (normalmente até 5000 observações)\n",
    "sample_size = min(5000, len(residuals))\n",
    "sample_residuals = residuals.sample(n=sample_size, random_state=42)\n",
    "stat, p_value = shapiro(sample_residuals)\n",
    "print(f\"Estatística Shapiro-Wilk: {stat:.4f}, p-valor: {p_value:.4f}\")\n",
    "if p_value > 0.05:\n",
    "    print(\"Os resíduos parecem seguir uma distribuição normal (não rejeita H0).\")\n",
    "else:\n",
    "    print(\"Os resíduos não seguem uma distribuição normal (rejeita H0).\")\n",
    "\n",
    "# Autocorrelação dos resíduos\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "plot_acf(residuals, ax=ax[0], lags=40, zero=False)\n",
    "ax[0].set_title('ACF dos Resíduos')\n",
    "plot_pacf(residuals, ax=ax[1], lags=40, zero=False, method='ywm')\n",
    "ax[1].set_title('PACF dos Resíduos')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cusum Simétrico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Supondo que 'residuals' é um pandas Series obtido anteriormente\n",
    "# Certifique-se de que os resíduos estão ordenados corretamente\n",
    "\n",
    "# Inicializar as colunas de CUSUM positivo e negativo\n",
    "cusum_positive = [0]\n",
    "cusum_negative = [0]\n",
    "\n",
    "# Iterar sobre os resíduos para calcular o CUSUM\n",
    "for residual in residuals:\n",
    "    # CUSUM positivo: soma acumulativa das diferenças positivas\n",
    "    s_pos = max(0, cusum_positive[-1] + residual)\n",
    "    cusum_positive.append(s_pos)\n",
    "    \n",
    "    # CUSUM negativo: soma acumulativa das diferenças negativas\n",
    "    s_neg = min(0, cusum_negative[-1] + residual)\n",
    "    cusum_negative.append(s_neg)\n",
    "\n",
    "# Remover o primeiro elemento (inicialização)\n",
    "cusum_positive = cusum_positive[1:]\n",
    "cusum_negative = cusum_negative[1:]\n",
    "\n",
    "# Adicionar ao DataFrame para facilitar o manuseio\n",
    "residuals_df = pd.DataFrame({\n",
    "    'Residuals': residuals,\n",
    "    'CUSUM_Positive': cusum_positive,\n",
    "    'CUSUM_Negative': cusum_negative\n",
    "}, index=residuals.index)\n",
    "\n",
    "# Exibir as primeiras linhas para verificação\n",
    "display(residuals_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar CUSUM Positivo e Negativo\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(residuals_df['CUSUM_Positive'], label='CUSUM Positivo', color='green')\n",
    "plt.plot(residuals_df['CUSUM_Negative'], label='CUSUM Negativo', color='red')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title('CUSUM dos Resíduos')\n",
    "plt.xlabel('Observações')\n",
    "plt.ylabel('Cumulative Sum')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicador de Volatilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Parte anterior: Cálculo dos Resíduos ---\n",
    "# Converter y para pandas Series (certifique-se de que 'y' está definido)\n",
    "y_series = pd.Series(y, name='y_true')\n",
    "\n",
    "# Verificar se Y_pred é um DataFrame com uma única coluna\n",
    "if isinstance(Y_pred, pd.DataFrame):\n",
    "    if Y_pred.shape[1] == 1:\n",
    "        # Converter para Series sem resetar o índice\n",
    "        Y_pred_series = Y_pred.iloc[:, 0]\n",
    "        Y_pred_series.name = 'y_pred'\n",
    "        print(f\"Convertido Y_pred para Series com comprimento {len(Y_pred_series)}.\")\n",
    "    else:\n",
    "        raise ValueError(\"Y_pred possui mais de uma coluna. Por favor, selecione a coluna correta para as previsões.\")\n",
    "elif isinstance(Y_pred, pd.Series):\n",
    "    Y_pred_series = Y_pred\n",
    "    Y_pred_series.name = 'y_pred'\n",
    "    print(f\"Y_pred já é uma Series com comprimento {len(Y_pred_series)}.\")\n",
    "else:\n",
    "    raise TypeError(\"Y_pred deve ser uma pandas Series ou DataFrame.\")\n",
    "\n",
    "# Verificar comprimentos\n",
    "len_y = len(y_series)\n",
    "len_Y_pred = len(Y_pred_series)\n",
    "\n",
    "print(f\"Comprimento de y_series: {len_y}\")\n",
    "print(f\"Comprimento de Y_pred_series: {len_Y_pred}\")\n",
    "\n",
    "# Calcular a diferença de comprimento\n",
    "diff = len_Y_pred - len_y\n",
    "\n",
    "if diff > 0:\n",
    "    print(f\"Y_pred_series é {diff} pontos maior que y_series. Truncando os últimos {diff} pontos de Y_pred_series.\")\n",
    "    Y_pred_aligned = Y_pred_series.iloc[:-diff]\n",
    "    y_aligned = y_series\n",
    "elif diff < 0:\n",
    "    print(f\"Y_pred_series é {abs(diff)} pontos menor que y_series. Truncando os últimos {abs(diff)} pontos de y_series.\")\n",
    "    y_aligned = y_series.iloc[:len_Y_pred]\n",
    "    Y_pred_aligned = Y_pred_series\n",
    "else:\n",
    "    print(\"y_series e Y_pred_series já estão alinhadas em comprimento.\")\n",
    "    y_aligned = y_series\n",
    "    Y_pred_aligned = Y_pred_series\n",
    "\n",
    "print(f\"Comprimento de y_aligned: {len(y_aligned)}\")\n",
    "print(f\"Comprimento de Y_pred_aligned: {len(Y_pred_aligned)}\")\n",
    "\n",
    "# Calcular os resíduos\n",
    "residuals = y_aligned - Y_pred_aligned\n",
    "\n",
    "# Exibir as primeiras linhas dos resíduos\n",
    "display(residuals.head())\n",
    "\n",
    "# --- Implementação do Indicador de Volatilidade ---\n",
    "# Definir os parâmetros para os indicadores\n",
    "window_size_std = 20  # Período para Desvio Padrão Móvel\n",
    "window_size_bb = 20   # Período para Bollinger Bands\n",
    "num_std_dev_bb = 2    # Número de desvios padrão para Bollinger Bands\n",
    "span_ewma = 20        # Span para EWMA\n",
    "window_size_atr = 14  # Período para ATR\n",
    "\n",
    "# --- 1. Desvio Padrão Móvel ---\n",
    "series['Rolling_STD'] = series['price_close'].rolling(window=window_size_std).std()\n",
    "\n",
    "# Verificar se a coluna foi criada\n",
    "if 'Rolling_STD' in series.columns:\n",
    "    print(\"Desvio Padrão Móvel calculado com sucesso.\")\n",
    "else:\n",
    "    print(\"Erro ao calcular o Desvio Padrão Móvel.\")\n",
    "\n",
    "# --- 2. Bollinger Bands ---\n",
    "rolling_mean = series['price_close'].rolling(window=window_size_bb).mean()\n",
    "rolling_std_bb = series['price_close'].rolling(window=window_size_bb).std()\n",
    "\n",
    "bollinger_upper = rolling_mean + (rolling_std_bb * num_std_dev_bb)\n",
    "bollinger_lower = rolling_mean - (rolling_std_bb * num_std_dev_bb)\n",
    "\n",
    "series['Rolling_Mean'] = rolling_mean\n",
    "series['Bollinger_Upper'] = bollinger_upper\n",
    "series['Bollinger_Lower'] = bollinger_lower\n",
    "\n",
    "# Verificar se as colunas foram criadas\n",
    "required_bb_columns = ['Rolling_Mean', 'Bollinger_Upper', 'Bollinger_Lower']\n",
    "if all(col in series.columns for col in required_bb_columns):\n",
    "    print(\"Bollinger Bands calculadas com sucesso.\")\n",
    "else:\n",
    "    missing_bb = [col for col in required_bb_columns if col not in series.columns]\n",
    "    print(f\"Erro ao calcular Bollinger Bands. Colunas faltantes: {missing_bb}\")\n",
    "\n",
    "# --- 3. EWMA Desvio Padrão ---\n",
    "series['EWMA_STD'] = series['price_close'].ewm(span=span_ewma, adjust=False).std()\n",
    "\n",
    "if 'EWMA_STD' in series.columns:\n",
    "    print(\"EWMA Desvio Padrão calculado com sucesso.\")\n",
    "else:\n",
    "    print(\"Erro ao calcular o EWMA Desvio Padrão.\")\n",
    "\n",
    "# --- 4. Average True Range (ATR) ---\n",
    "required_atr_columns = ['price_high', 'price_low', 'price_close']\n",
    "if all(col in series.columns for col in required_atr_columns):\n",
    "    high_low = series['price_high'] - series['price_low']\n",
    "    high_prev_close = (series['price_high'] - series['price_close'].shift()).abs()\n",
    "    low_prev_close = (series['price_low'] - series['price_close'].shift()).abs()\n",
    "    true_range = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1)\n",
    "    series['ATR'] = true_range.rolling(window=window_size_atr).mean()\n",
    "    print(\"Average True Range (ATR) calculado com sucesso.\")\n",
    "else:\n",
    "    missing_atr = [col for col in required_atr_columns if col not in series.columns]\n",
    "    print(f\"Não foi possível calcular o ATR. Colunas faltantes: {missing_atr}\")\n",
    "\n",
    "# --- 5. Visualizar os Indicadores de Volatilidade ---\n",
    "\n",
    "# a. Desvio Padrão Móvel\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "plt.plot(series['Rolling_STD'], label=f'Desvio Padrão Móvel ({window_size_std} períodos)', color='orange')\n",
    "plt.title('Desvio Padrão Móvel da Série de Preços')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço / Volatilidade')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# b. Bollinger Bands\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "plt.plot(series['Rolling_Mean'], label=f'Média Móvel ({window_size_bb} períodos)', color='orange')\n",
    "plt.plot(series['Bollinger_Upper'], label='Bollinger Upper', color='green')\n",
    "plt.plot(series['Bollinger_Lower'], label='Bollinger Lower', color='red')\n",
    "plt.fill_between(series.index, series['Bollinger_Lower'], series['Bollinger_Upper'], color='lightgray')\n",
    "plt.title('Bollinger Bands da Série de Preços')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# c. EWMA Desvio Padrão\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "plt.plot(series['EWMA_STD'], label=f'EWMA Desvio Padrão (span={span_ewma})', color='purple')\n",
    "plt.title('EWMA Desvio Padrão da Série de Preços')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço / Volatilidade')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# d. ATR (Opcional)\n",
    "if 'ATR' in series.columns:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "    plt.plot(series['ATR'], label=f'ATR ({window_size_atr} períodos)', color='magenta')\n",
    "    plt.title('Average True Range (ATR) da Série de Preços')\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Preço / ATR')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- 6. Integrar os Indicadores no Modelo de Regressão ---\n",
    "\n",
    "# a. Selecionar as features disponíveis\n",
    "features = ['Rolling_STD', 'Rolling_Mean', 'Bollinger_Upper', 'Bollinger_Lower', 'EWMA_STD']\n",
    "\n",
    "# Adicionar 'ATR' se estiver disponível\n",
    "if 'ATR' in series.columns:\n",
    "    features.append('ATR')\n",
    "\n",
    "# Verificar quais features estão presentes no DataFrame\n",
    "available_features = [feature for feature in features if feature in series.columns]\n",
    "missing_features = [feature for feature in features if feature not in series.columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"As seguintes features estão faltando e serão ignoradas: {missing_features}\")\n",
    "\n",
    "print(f\"Features disponíveis para modelagem: {available_features}\")\n",
    "\n",
    "# b. Preparar os Dados para o Modelo\n",
    "X_features = series[available_features].dropna()\n",
    "print(f\"\\nNúmero de linhas em X_features após dropna(): {len(X_features)}\")\n",
    "\n",
    "# Encontrar os índices comuns entre X_features e y_aligned\n",
    "common_indices = X_features.index.intersection(y_aligned.index)\n",
    "print(f\"Número de índices comuns: {len(common_indices)}\")\n",
    "\n",
    "# Selecionar apenas os índices comuns\n",
    "X_features_aligned = X_features.loc[common_indices]\n",
    "y_features_aligned = y_aligned.loc[common_indices]\n",
    "\n",
    "print(f\"Comprimento de X_features_aligned: {len(X_features_aligned)}\")\n",
    "print(f\"Comprimento de y_features_aligned: {len(y_features_aligned)}\")\n",
    "\n",
    "# Verificar se os índices estão alinhados\n",
    "if len(X_features_aligned) != len(y_features_aligned):\n",
    "    print(\"Os dados das features e da variável alvo ainda não estão alinhados.\")\n",
    "else:\n",
    "    print(\"X_features e y_features estão alinhados corretamente.\")\n",
    "\n",
    "# c. Preprocessamento e PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_features_aligned)\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"\\nVariância explicada acumulada:\", cumulative_variance)\n",
    "\n",
    "# Determinar o número de componentes para 95% da variância\n",
    "n_components_var = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Número ótimo de componentes (95% da variância explicada): {n_components_var}\")\n",
    "\n",
    "# Reduzir a dimensionalidade\n",
    "pca_reduced = PCA(n_components=n_components_var)\n",
    "X_reduced = pca_reduced.fit_transform(X_scaled)\n",
    "print(f\"Forma da matriz após PCA: {X_reduced.shape}\")\n",
    "\n",
    "# d. Modelagem com Regressão Linear\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X_reduced, y_features_aligned, cv=5, scoring='neg_mean_squared_error')\n",
    "mse_mean = -np.mean(scores)\n",
    "print(f\"MSE médio (5-fold CV): {mse_mean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Política das 3 Barreiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Parte anterior: Cálculo dos Resíduos ---\n",
    "# Converter y para pandas Series (certifique-se de que 'y' está definido)\n",
    "y_series = pd.Series(y, name='y_true')\n",
    "\n",
    "# Verificar se Y_pred é um DataFrame com uma única coluna\n",
    "if isinstance(Y_pred, pd.DataFrame):\n",
    "    if Y_pred.shape[1] == 1:\n",
    "        # Converter para Series sem resetar o índice\n",
    "        Y_pred_series = Y_pred.iloc[:, 0]\n",
    "        Y_pred_series.name = 'y_pred'\n",
    "        print(f\"Convertido Y_pred para Series com comprimento {len(Y_pred_series)}.\")\n",
    "    else:\n",
    "        raise ValueError(\"Y_pred possui mais de uma coluna. Por favor, selecione a coluna correta para as previsões.\")\n",
    "elif isinstance(Y_pred, pd.Series):\n",
    "    Y_pred_series = Y_pred\n",
    "    Y_pred_series.name = 'y_pred'\n",
    "    print(f\"Y_pred já é uma Series com comprimento {len(Y_pred_series)}.\")\n",
    "else:\n",
    "    raise TypeError(\"Y_pred deve ser uma pandas Series ou DataFrame.\")\n",
    "\n",
    "# Verificar comprimentos\n",
    "len_y = len(y_series)\n",
    "len_Y_pred = len(Y_pred_series)\n",
    "\n",
    "print(f\"Comprimento de y_series: {len_y}\")\n",
    "print(f\"Comprimento de Y_pred_series: {len_Y_pred}\")\n",
    "\n",
    "# Calcular a diferença de comprimento\n",
    "diff = len_Y_pred - len_y\n",
    "\n",
    "if diff > 0:\n",
    "    print(f\"Y_pred_series é {diff} pontos maior que y_series. Truncando os últimos {diff} pontos de Y_pred_series.\")\n",
    "    Y_pred_aligned = Y_pred_series.iloc[:-diff]\n",
    "    y_aligned = y_series\n",
    "elif diff < 0:\n",
    "    print(f\"Y_pred_series é {abs(diff)} pontos menor que y_series. Truncando os últimos {abs(diff)} pontos de y_series.\")\n",
    "    y_aligned = y_series.iloc[:len_Y_pred]\n",
    "    Y_pred_aligned = Y_pred_series\n",
    "else:\n",
    "    print(\"y_series e Y_pred_series já estão alinhadas em comprimento.\")\n",
    "    y_aligned = y_series\n",
    "    Y_pred_aligned = Y_pred_series\n",
    "\n",
    "print(f\"Comprimento de y_aligned: {len(y_aligned)}\")\n",
    "print(f\"Comprimento de Y_pred_aligned: {len(Y_pred_aligned)}\")\n",
    "\n",
    "# Calcular os resíduos\n",
    "residuals = y_aligned - Y_pred_aligned\n",
    "\n",
    "# Adicionar os resíduos ao DataFrame 'series'\n",
    "series['Residuals'] = residuals\n",
    "\n",
    "# Verificar se todos os índices de residuals estão em series\n",
    "missing_indices = residuals.index.difference(series.index)\n",
    "if not missing_indices.empty:\n",
    "    print(f\"\\nÍndices faltantes em 'series' que estão em 'residuals': {missing_indices.tolist()}\")\n",
    "    # Remover esses índices de residuals\n",
    "    residuals = residuals.drop(index=missing_indices)\n",
    "    # Atualizar o DataFrame 'series' para refletir a remoção\n",
    "    series = series.drop(index=missing_indices)\n",
    "    print(f\"Residuals após remoção dos índices faltantes: {len(residuals)}\")\n",
    "else:\n",
    "    print(\"\\nTodos os índices de 'residuals' estão presentes em 'series'.\")\n",
    "\n",
    "# --- Implementação do Indicador de Volatilidade ---\n",
    "# Definir os parâmetros para os indicadores\n",
    "window_size_std = 20  # Período para Desvio Padrão Móvel\n",
    "window_size_bb = 20   # Período para Bollinger Bands\n",
    "num_std_dev_bb = 2    # Número de desvios padrão para Bollinger Bands\n",
    "span_ewma = 20        # Span para EWMA\n",
    "window_size_atr = 14  # Período para ATR\n",
    "\n",
    "# --- 1. Desvio Padrão Móvel ---\n",
    "series['Rolling_STD'] = series['price_close'].rolling(window=window_size_std).std()\n",
    "\n",
    "# Verificar se a coluna foi criada\n",
    "if 'Rolling_STD' in series.columns:\n",
    "    print(\"Desvio Padrão Móvel calculado com sucesso.\")\n",
    "else:\n",
    "    print(\"Erro ao calcular o Desvio Padrão Móvel.\")\n",
    "\n",
    "# --- 2. Bollinger Bands ---\n",
    "rolling_mean = series['price_close'].rolling(window=window_size_bb).mean()\n",
    "rolling_std_bb = series['price_close'].rolling(window=window_size_bb).std()\n",
    "\n",
    "bollinger_upper = rolling_mean + (rolling_std_bb * num_std_dev_bb)\n",
    "bollinger_lower = rolling_mean - (rolling_std_bb * num_std_dev_bb)\n",
    "\n",
    "series['Rolling_Mean'] = rolling_mean\n",
    "series['Bollinger_Upper'] = bollinger_upper\n",
    "series['Bollinger_Lower'] = bollinger_lower\n",
    "\n",
    "# Verificar se as colunas foram criadas\n",
    "required_bb_columns = ['Rolling_Mean', 'Bollinger_Upper', 'Bollinger_Lower']\n",
    "if all(col in series.columns for col in required_bb_columns):\n",
    "    print(\"Bollinger Bands calculadas com sucesso.\")\n",
    "else:\n",
    "    missing_bb = [col for col in required_bb_columns if col not in series.columns]\n",
    "    print(f\"Erro ao calcular Bollinger Bands. Colunas faltantes: {missing_bb}\")\n",
    "\n",
    "# --- 3. EWMA Desvio Padrão ---\n",
    "series['EWMA_STD'] = series['price_close'].ewm(span=span_ewma, adjust=False).std()\n",
    "\n",
    "if 'EWMA_STD' in series.columns:\n",
    "    print(\"EWMA Desvio Padrão calculado com sucesso.\")\n",
    "else:\n",
    "    print(\"Erro ao calcular o EWMA Desvio Padrão.\")\n",
    "\n",
    "# --- 4. Average True Range (ATR) ---\n",
    "required_atr_columns = ['price_high', 'price_low', 'price_close']\n",
    "if all(col in series.columns for col in required_atr_columns):\n",
    "    high_low = series['price_high'] - series['price_low']\n",
    "    high_prev_close = (series['price_high'] - series['price_close'].shift()).abs()\n",
    "    low_prev_close = (series['price_low'] - series['price_close'].shift()).abs()\n",
    "    true_range = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1)\n",
    "    series['ATR'] = true_range.rolling(window=window_size_atr).mean()\n",
    "    print(\"Average True Range (ATR) calculado com sucesso.\")\n",
    "else:\n",
    "    missing_atr = [col for col in required_atr_columns if col not in series.columns]\n",
    "    print(f\"Não foi possível calcular o ATR. Colunas faltantes: {missing_atr}\")\n",
    "\n",
    "# --- 5. Visualizar os Indicadores de Volatilidade ---\n",
    "# a. Desvio Padrão Móvel\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "plt.plot(series['Rolling_STD'], label=f'Desvio Padrão Móvel ({window_size_std} períodos)', color='orange')\n",
    "plt.title('Desvio Padrão Móvel da Série de Preços')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço / Volatilidade')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# b. Bollinger Bands\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "plt.plot(series['Rolling_Mean'], label=f'Média Móvel ({window_size_bb} períodos)', color='orange')\n",
    "plt.plot(series['Bollinger_Upper'], label='Bollinger Upper', color='green')\n",
    "plt.plot(series['Bollinger_Lower'], label='Bollinger Lower', color='red')\n",
    "plt.fill_between(series.index, series['Bollinger_Lower'], series['Bollinger_Upper'], color='lightgray')\n",
    "plt.title('Bollinger Bands da Série de Preços')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# c. EWMA Desvio Padrão\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "plt.plot(series['EWMA_STD'], label=f'EWMA Desvio Padrão (span={span_ewma})', color='purple')\n",
    "plt.title('EWMA Desvio Padrão da Série de Preços')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço / Volatilidade')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# d. ATR (Opcional)\n",
    "if 'ATR' in series.columns:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(series['price_close'], label='Preço de Fechamento', color='blue')\n",
    "    plt.plot(series['ATR'], label=f'ATR ({window_size_atr} períodos)', color='magenta')\n",
    "    plt.title('Average True Range (ATR) da Série de Preços')\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Preço / ATR')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- 6. Calcular o CUSUM dos Resíduos ---\n",
    "# Parâmetros para o CUSUM\n",
    "k = 0.5  # Tolerância, ajuste conforme necessário\n",
    "\n",
    "# Inicializar as colunas de CUSUM positivo e negativo como float\n",
    "series['CUSUM_Positive'] = 0.0\n",
    "series['CUSUM_Negative'] = 0.0\n",
    "\n",
    "# Calcular o CUSUM usando iterrows()\n",
    "for i in range(1, len(series)):\n",
    "    current_index = series.index[i]\n",
    "    previous_index = series.index[i-1]\n",
    "    \n",
    "    try:\n",
    "        # Calcular CUSUM Positivo\n",
    "        series.at[current_index, 'CUSUM_Positive'] = max(\n",
    "            0.0, \n",
    "            series.at[previous_index, 'CUSUM_Positive'] + residuals.loc[current_index] - k\n",
    "        )\n",
    "        \n",
    "        # Calcular CUSUM Negativo\n",
    "        series.at[current_index, 'CUSUM_Negative'] = min(\n",
    "            0.0, \n",
    "            series.at[previous_index, 'CUSUM_Negative'] + residuals.loc[current_index] + k\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        print(f\"Erro ao acessar o índice {current_index}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado ao calcular CUSUM para o índice {current_index}: {e}\")\n",
    "\n",
    "# --- 7. Definir as Barreiras ---\n",
    "# Definir os múltiplos para as barreiras\n",
    "barrier_levels = {\n",
    "    'alert': 1,      # 1x a volatilidade\n",
    "    'action': 2,     # 2x a volatilidade\n",
    "    'critical': 3    # 3x a volatilidade\n",
    "}\n",
    "\n",
    "# Calcular as barreiras positivas e negativas\n",
    "for level, multiplier in barrier_levels.items():\n",
    "    series[f'Barreira_Pos_{level}'] = series['Rolling_STD'] * multiplier\n",
    "    series[f'Barreira_Neg_{level}'] = -series['Rolling_STD'] * multiplier\n",
    "\n",
    "# --- 8. Aplicar a Política das 3 Barreiras ---\n",
    "# Inicializar uma coluna para o gatilho\n",
    "series['Gatilho'] = None\n",
    "\n",
    "# Função para aplicar a política das 3 barreiras\n",
    "def aplicar_politica(row):\n",
    "    # CUSUM Positivo\n",
    "    if row['CUSUM_Positive'] > row['Barreira_Pos_alert']:\n",
    "        if row['CUSUM_Positive'] > row['Barreira_Pos_critical']:\n",
    "            return 'Crítica Positiva'\n",
    "        elif row['CUSUM_Positive'] > row['Barreira_Pos_action']:\n",
    "            return 'Ação Positiva'\n",
    "        else:\n",
    "            return 'Alerta Positivo'\n",
    "    # CUSUM Negativo\n",
    "    elif row['CUSUM_Negative'] < row['Barreira_Neg_alert']:\n",
    "        if row['CUSUM_Negative'] < row['Barreira_Neg_critical']:\n",
    "            return 'Crítica Negativa'\n",
    "        elif row['CUSUM_Negative'] < row['Barreira_Neg_action']:\n",
    "            return 'Ação Negativa'\n",
    "        else:\n",
    "            return 'Alerta Negativo'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Aplicar a política das 3 barreiras\n",
    "series['Gatilho'] = series.apply(aplicar_politica, axis=1)\n",
    "\n",
    "# --- 9. Visualizar os Gatilhos ---\n",
    "# a. CUSUM Positivo com Barreiras e Gatilhos\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['CUSUM_Positive'], label='CUSUM Positivo', color='green')\n",
    "plt.plot(series['Barreira_Pos_alert'], label='Barreira Positiva - Alerta', linestyle='--', color='orange')\n",
    "plt.plot(series['Barreira_Pos_action'], label='Barreira Positiva - Ação', linestyle='--', color='red')\n",
    "plt.plot(series['Barreira_Pos_critical'], label='Barreira Positiva - Crítica', linestyle='--', color='purple')\n",
    "\n",
    "# Marcadores para os gatilhos positivos\n",
    "gatilhos_pos = series[series['Gatilho'].isin(['Alerta Positivo', 'Ação Positiva', 'Crítica Positiva'])]\n",
    "plt.scatter(\n",
    "    gatilhos_pos.index, \n",
    "    gatilhos_pos['CUSUM_Positive'], \n",
    "    c=gatilhos_pos['Gatilho'].map({\n",
    "        'Alerta Positivo': 'yellow', \n",
    "        'Ação Positiva': 'orange', \n",
    "        'Crítica Positiva': 'red'\n",
    "    }), \n",
    "    label='Gatilho Positivo', \n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title('CUSUM Positivo com Barreiras e Gatilhos')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Cumulative Sum')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# b. CUSUM Negativo com Barreiras e Gatilhos\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(series['CUSUM_Negative'], label='CUSUM Negativo', color='red')\n",
    "plt.plot(series['Barreira_Neg_alert'], label='Barreira Negativa - Alerta', linestyle='--', color='orange')\n",
    "plt.plot(series['Barreira_Neg_action'], label='Barreira Negativa - Ação', linestyle='--', color='blue')\n",
    "plt.plot(series['Barreira_Neg_critical'], label='Barreira Negativa - Crítica', linestyle='--', color='purple')\n",
    "\n",
    "# Marcadores para os gatilhos negativos\n",
    "gatilhos_neg = series[series['Gatilho'].isin(['Alerta Negativo', 'Ação Negativa', 'Crítica Negativa'])]\n",
    "plt.scatter(\n",
    "    gatilhos_neg.index, \n",
    "    gatilhos_neg['CUSUM_Negative'], \n",
    "    c=gatilhos_neg['Gatilho'].map({\n",
    "        'Alerta Negativo': 'yellow', \n",
    "        'Ação Negativa': 'blue', \n",
    "        'Crítica Negativa': 'purple'\n",
    "    }), \n",
    "    label='Gatilho Negativo', \n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title('CUSUM Negativo com Barreiras e Gatilhos')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Cumulative Sum')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- 10. Exibir os Eventos de Gatilho ---\n",
    "# Filtrar os eventos de gatilho\n",
    "eventos_gatilho = series[series['Gatilho'].notnull()][['Gatilho']]\n",
    "\n",
    "print(\"Eventos de Gatilho Detectados:\")\n",
    "display(eventos_gatilho)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
